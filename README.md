# MOMO_2
Practice tasks of ML studing (Master's Degree)

## Практическая работа №1
<details>

### Вам необходимо:
1. Ознакомиться с содержанием демонстрационных блокнотов.

2. Создать новый блокнот, импортировать необходимые библиотеки (необязательно копировать все — только нужные функции и/или классы).

3. Выбрать набор данных для классификации (когда целевая переменная имеет конечное число возможных значений) или регрессии (когда их бесконечно):

* Возможно использование набора данных Cars Moldova. При выборе этого набора обязательно использовать новые признаки в дополнение к тем, что приводились в демонстрации.
* Возможно использование данных, связанных с вашими проектными работами или вашей работой (если, разумеется, этими данными можно делиться).
* Возможно использование наборов данных из открытых источников (OpenML, Kaggle). Основной критерий — достаточно много признаков и немало данных. Условно: от 5 различных признаков (без учета целевой переменной) и от 1000 строк данных.
* Нельзя использовать наборы данных, которые приводятся в соревнованиях в этом семестре.
4. Выполнить адекватную предварительную обработку данных: 

* Если вы выполняли ее раньше в 1 семестре, в рамках проекта №1, сделать ссылку и продемонстрировать только итоговый результат без предварительных вычислений и визуализаций.

5. Сформулировать начальные гипотезы: какие признаки могут быть полезны для решения поставленной задачи.

* В случае, если подобный анализ был адекватно проведен в 1 семестре, в рамках проекта №1, сделать ссылку и продемонстрировать только итоговый результат без предварительных вычислений и визуализаций.

6. Разбить данные на тренировочную и валидационную выборку.

7. Выбрать модель, с помощью который вы будете анализировать данные. На выбор:

* метод к-ближайших соседей,
* метод опорных векторов,
* деревья решений.

8. Обучить модель, которая будет базовой (baseline). Как правило, это самая «простая» модель (например, только числовые признаки, гиперпараметры модели по умолчанию). Необходимо проанализировать:

* метрики на тренировочных и валидационных данных;
* визуализации класса PredictionErrorDisplay которые строят зависимости предсказаний моделей от реальных целевых значений  для задачи регрессии;
* classification_report или матрицу ошибок для задачи классификации;
* для деревьев решений обязателен анализ значимости признаков (feature_importance_).

9. Сделать выводы о полученном решении. Ожидаются следующие комментарии:

* адекватные ли метрики; 
* как распределены ошибки модели для задачи регрессии;
* ошибок для моделей какого класса больше для задачи классификации;
* есть ли что-то общее у ошибочных предсказаний.

10. Попытаться улучшить качество модели:

* добавить в модель категориальные признаки;
* использовать другие варианты предварительной обработки признаков;
* использовать преобразование PolinomialFeatures для числовых признаков;
* оптимизировать гиперпараметры моделей машинного обучения; 
* использовать трансформацию целевой переменной TransformedTargetRegressor для задачи регрессии.

11. Сделать выводы о полученном решении. 

12. *Если вы анализировали тот же набор данных, что и в 1 семестре.* Сравнить результаты с линейной или логистической регрессией, полученной вами ранее.
  
</details>


## Практическая работа №2
<details>

### Соревнование № 1. Регрессия

В этом соревновании вам предстоит показать навыки обучения моделей машинного обучения для регрессии. Для успешного прохождения соревнования вам также придется генерировать признаки для модели.

https://www.kaggle.com/competitions/urfusf2024reg

</details>

## Практическая работа №3
<details>

### Соревнование № 2. Кластеризация

В этом соревновании вам предстоит показать навыки владения моделями машинного обучения для кластеризации данных.

https://www.kaggle.com/competitions/urfusf2024clustering

</details>

## Практическая работа №4
<details>

### Вам необходимо:
1. Ознакомиться с содержанием демонстрационных блокнотов.

2. Создать новый блокнот, импортировать необходимые библиотеки (необязательно копировать все — только нужные функции и/или классы).

3. Выбрать MNIST-подобный набор данных. Например:

* Fashion-MNIST (про одежду);
* Kuzushiji-MNIST (иероглифы);
* UMIST_Faces_Cropped (про лица);
* SignMNIST (про буквы);
* Olivetti_Faces (еще немного лиц).

4. Применить метод визуализации t-SNE. Проанализировать результат:

* сделать визуализацию, которая использует метки классов для подсветки данных разным цветом;
* можно изменить значение perplexity для улучшения результата.

5. Выполнить кластеризацию любым методом из второго семестра:

* подобрать оптимальные гиперпараметры выбранного метода кластеризации,
* проанализировать связь кластеров с целевой переменной, 
* проанализировать ошибочные «предсказания».

6. Сделать выводы о полученном решении. Ожидаются следующие комментарии:

* смог ли метод визуализации t-SNE выделить отдельные группы данных,
* насколько целесообразно анализировать данный набор методом кластеризации,
* какое число кластеров оптимально,
* какая связь между номерами кластеров и целевой переменной.
_Примечание: если вы анализировали тот же набор данных, что и в 1 семестре, сравните результаты визуализации t-SNE с уменьшением размерности методом главных компонент._

</details>

## Практическая работа №5
<details>

### Вам необходимо:
1. Ознакомиться с содержанием демонстрационных блокнотов.
2. Создать новый блокнот, импортировать необходимые библиотеки (необязательно копировать все — только нужные функции и/или классы).
3. Выбрать набор данных для классификации (когда целевая переменная имеет конечное число возможных значений) или регрессии (когда их бесконечно):
* Возможно использование набора данных Cars Moldova. При выборе этого набора обязательно использовать новые признаки в дополнение к тем, что приводились в демонстрации.
* Возможно использование данных, связанных с вашими проектными работами или профессиональной деятельностью (если, разумеется, этими данными можно делиться).
* Возможно использование наборов данных из открытых источников (OpenML, Kaggle). Основной критерий — достаточно много признаков и немало данных. Условно: от 5 различных признаков (без учета целевой переменной) и от 1000 строк данных.
* Нельзя использовать наборы данных, которые приводятся в соревнованиях в этом семестре.

4. Выполнить адекватную предварительную обработку данных:
* Если вы выполняли ее раньше в 1 семестре, в рамках проекта №1, сделайте ссылку и продемонстрируйте только итоговый результат без предварительных вычислений и визуализаций.

5. Сформулировать начальные гипотезы: какие признаки могут быть полезны для решения поставленной задачи.
* В случае, если подобный анализ был адекватно проведен в 1 семестре, в рамках проекта №1, сделайте ссылку и продемонстрируйте только итоговый результат без предварительных вычислений и визуализаций.

6. Разбить данные на тренировочную и валидационную выборку.
7. Для получения максимального балла необходимо выбрать 2 модели, с помощью которых вы будете анализировать данные. Вам нужно выбрать 1 ансамблевую модель из scikit-learn и 1 «внешнюю» модель:
* случайный Лес (scikit-learn);
* градиентный бустинг (scikit-learn);
* градиентный бустинг основанный на гистограммах (scikit-learn);
* градиентный бустинг CatBoost;
* градиентный бустинг XGBoost;
* градиентный бустинг LightGBM.
Для каждой из двух выбранных ансамблевых моделей необходимо выполнить аналогичный перечень шагов, как и ранее.


8. Обучить модель, которая будет базовой (baseline). Как правило, это самая «простая» модель (например, только числовые признаки, гиперпараметры модели по умолчанию). Необходимо проанализировать:
* метрики на тренировочных и валидационных данных;
* визуализации класса PredictionErrorDisplay, которые строят зависимости предсказаний моделей от реальных целевых значений для задачи регрессии;
* classification_report или матрицу ошибок для задачи классификации;
* обязателен анализ значимости признаков (feature_importance_).

9. Сделать выводы о полученном решении. Ожидаются следующие комментарии:
* адекватны ли метрики;
* как распределены ошибки модели для задачи регрессии;
* для какого класса моделей количество ошибок в задаче классификации больше;
* есть ли что-то общее у ошибочных предсказаний.

10. Попытаться улучшить качество модели:
* добавить в модель категориальные признаки;
* использовать другие варианты предварительной обработки признаков;
* использовать преобразование PolinomialFeatures для числовых признаков;
* оптимизировать гиперпараметры моделей машинного обучения;
* использовать трансформацию целевой переменной TransformedTargetRegressor для задачи регрессии.

11. Сделать выводы о полученном решении.
* Для получения максимальных баллов вам необходимо выполнить сравнение двух выбранных ансамблевых моделей между собой, а также сравнить результат обучения ансамблевых моделей с теми, которые были обучены ранее (как в рамках 1 семестра, так и в рамках домашнего задания №1 для этого семестра). Ожидаются комментарии по * сравнению метрик; распределению ошибок моделей; по тому, какие признаки оказались наиболее «полезными» для разных моделей.
</details>

